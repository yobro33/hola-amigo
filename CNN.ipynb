{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ps0tujEa8r8j"
      },
      "outputs": [],
      "source": [
        "# CNN test. First convolutional network - Quinn Vaughn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Make matplotlib charts show in the notebook\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "dTgIcBDX879y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "\n",
        "# Best and Worst options from an image\n",
        "def show_min_max(array, i):\n",
        "  random_image = array[i]\n",
        "  print(random_image.min(), random_image.max())\n",
        "\n",
        "# Plots image from array\n",
        "def plot_image(array, i, labels):\n",
        "  plt.imshow(np.squeeze(array[i]))\n",
        "  plt.title(\" Digit \" + str(labels[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fOQlp9-O89Eh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep track of image size (28 x 28 px)\n",
        "img_rows, img_cols = 28,28\n",
        "\n",
        "# Set output class size\n",
        "num_classes = 10\n",
        "\n",
        "# Load the data\n",
        "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
        "# Create backup of untouched data\n",
        "(train_images_backup,train_labels_backup),(test_images_backup,test_labels_backup) = mnist.load_data()\n",
        "\n",
        "# Log shape of train and test images\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "\n",
        "# Reshape train + test images\n",
        "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "# Keep track of shape of the object\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# Plot the 100th char\n",
        "plot_image(train_images, 100, train_labels)\n",
        "show_min_max(train_images, 100)\n",
        "\n",
        "# Convert data to float 32\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "\n",
        "# Divide by 255\n",
        "train_images /= 255\n",
        "test_images /= 255\n",
        "\n",
        "# Graph image and min max values\n",
        "plot_image(train_images, 100, train_labels)\n",
        "show_min_max(train_images, 100)\n",
        "\n",
        "# Utilize one hot encoding to increase detection success\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "h6BHlzHE8_yA",
        "outputId": "4327d52b-fbfc-404c-c8f6-c443f32f8aab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 255\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN BLOCK\n",
        "\n",
        "# Define epochs\n",
        "epochs = 10\n",
        "\n",
        "# Both DNN and CNN use sequential, so we are gonna define the model as sequential\n",
        "model = Sequential()\n",
        "\n",
        "# Add Conv2D layer\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape))\n",
        "\n",
        "# Add pooling layer (Downscales images)\n",
        "model.add(MaxPooling2D(pool_size=(2,2), ))\n",
        "\n",
        "# Add another Conv2D layer\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "# Add a dropout layer, drops out 30% of the neurons forcing them to adapt\n",
        "model.add(Dropout(rate=0.3,))\n",
        "\n",
        "# Add another Conv2D layer\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\"))"
      ],
      "metadata": {
        "id": "9KodFs5j9VxZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN layer\n",
        "\n",
        "# Flatten data to be readable\n",
        "model.add(Flatten())\n",
        "\n",
        "# First layer of DNN, 32 neurons relu.\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "aWMC0LmDAPk6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aoz_7Y_6CUOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy7BdnguArES",
        "outputId": "4a301381-b671-4924-883a-53999be78924"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 9, 32)          18464     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2592)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                82976     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,586\n",
            "Trainable params: 120,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model to be trained\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VgzH8OzEAvnx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_images, train_labels, batch_size=64, epochs=epochs, validation_data=(test_images, test_labels), shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytI8PbU5BdDh",
        "outputId": "79fbe828-4e7a-47e9-b1af-e0107de20cf6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 19s 6ms/step - loss: 0.1709 - accuracy: 0.9471 - val_loss: 0.0476 - val_accuracy: 0.9840\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0492 - accuracy: 0.9849 - val_loss: 0.0363 - val_accuracy: 0.9879\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.0401 - val_accuracy: 0.9874\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.0297 - val_accuracy: 0.9906\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.0281 - val_accuracy: 0.9912\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0272 - val_accuracy: 0.9911\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0302 - val_accuracy: 0.9908\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0317 - val_accuracy: 0.9920\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0321 - val_accuracy: 0.9922\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0297 - val_accuracy: 0.9934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d800ef950>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "\n",
        "# Get the model scores\n",
        "scores = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "print(\"Test accuracy: %s\"%scores[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k155nSoZB85O",
        "outputId": "63f44e47-e5e7-467a-8230-74bc1f86bc8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.993399977684021\n"
          ]
        }
      ]
    }
  ]
}